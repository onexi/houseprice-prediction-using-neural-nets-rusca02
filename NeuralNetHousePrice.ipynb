{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4712</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10659</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>COD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9786</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>91000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6762</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>206000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0       1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1       2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2       3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3       4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4       5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "..    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "995   996          50       RL         51.0     4712   Pave   NaN      IR1   \n",
       "996   997          20       RL          NaN    10659   Pave   NaN      IR1   \n",
       "997   998          20       RL          NaN    11717   Pave   NaN      IR1   \n",
       "998   999          30       RM         60.0     9786   Pave   NaN      Reg   \n",
       "999  1000          20       RL         64.0     6762   Pave   NaN      Reg   \n",
       "\n",
       "    LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "..          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "995         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "996         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "997         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "998         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "999         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "    MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0        2   2008        WD         Normal     208500  \n",
       "1        5   2007        WD         Normal     181500  \n",
       "2        9   2008        WD         Normal     223500  \n",
       "3        2   2006        WD        Abnorml     140000  \n",
       "4       12   2008        WD         Normal     250000  \n",
       "..     ...    ...       ...            ...        ...  \n",
       "995      8   2006        WD        Abnorml     121600  \n",
       "996      1   2006       COD         Normal     136500  \n",
       "997      2   2009        WD         Normal     185000  \n",
       "998      5   2006        WD         Normal      91000  \n",
       "999      2   2010        WD         Normal     206000  \n",
       "\n",
       "[1000 rows x 81 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Load the dataset\n",
    "# -----------------------------\n",
    "# Replace 'house_prices.csv' with the path to your dataset.\n",
    "data = pd.read_csv('train.csv')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
      "       'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
      "       'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
      "       'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars',\n",
      "       'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
      "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2. Data Cleaning\n",
    "# -----------------------------\n",
    "# Select only numeric columns that have no missing data.\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "#keep only columns with no missing values\n",
    "clean_numeric_cols = [col for col in numeric_cols if data[col].isna().sum() == 0]\n",
    "\n",
    "#create a cleared dataset with only numeric columns\n",
    "data_clean = data[clean_numeric_cols]\n",
    "\n",
    "\n",
    "# Ensure that the target column 'price' is present.\n",
    "if 'SalePrice' not in data_clean.columns:\n",
    "    raise ValueError(\"The target column 'price' is not present in the complete numeric data.\")\n",
    "print(data_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected top 4 features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. Feature Selection\n",
    "# -----------------------------\n",
    "# Compute the correlation matrix using only the cleaned numeric data.\n",
    "corr_matrix = data_clean.corr()\n",
    "\n",
    "# Compute absolute correlations of features with the target and drop the target itself.\n",
    "target_corr = corr_matrix['SalePrice'].drop('SalePrice').abs().sort_values(ascending=False)\n",
    "\n",
    "# Select only the top 4 features with the highest correlation with 'SalesPrice'\n",
    "top4_features = target_corr.head(4).index\n",
    "print(\"Selected top 4 features:\", list(top4_features))\n",
    "\n",
    "# Define input features (X) and target variable (y).\n",
    "X = data_clean[top4_features].values\n",
    "y = data_clean['SalePrice'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 4) (200, 4)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. Data Preprocessing\n",
    "# -----------------------------\n",
    "# Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features to improve training stability.\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "# ✅ Standardize SalePrice (y values)\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = scaler_y.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 4]) torch.Size([800, 1]) torch.Size([200, 4]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# Convert the numpy arrays to PyTorch tensors.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset and DataLoader for batch processing.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(X_train_tensor.shape, y_train_tensor.shape, X_test_tensor.shape, y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5. Define the Neural Network Model\n",
    "# -----------------------------\n",
    "class HousePriceModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HousePriceModel, self).__init__()\n",
    "        #Deeper architecture for better learning\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)  # Output layer for regression\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)  # 20% dropout\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HousePriceModel(input_dim=X_train.shape[1]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.6134\n",
      "Epoch [20/1000], Loss: 0.4106\n",
      "Epoch [30/1000], Loss: 0.3894\n",
      "Epoch [40/1000], Loss: 0.3609\n",
      "Epoch [50/1000], Loss: 0.3652\n",
      "Epoch [60/1000], Loss: 0.3626\n",
      "Epoch [70/1000], Loss: 0.3615\n",
      "Epoch [80/1000], Loss: 0.3448\n",
      "Epoch [90/1000], Loss: 0.3040\n",
      "Epoch [100/1000], Loss: 0.3598\n",
      "Epoch [110/1000], Loss: 0.3837\n",
      "Epoch [120/1000], Loss: 0.3508\n",
      "Epoch [130/1000], Loss: 0.3433\n",
      "Epoch [140/1000], Loss: 0.3998\n",
      "Epoch [150/1000], Loss: 0.4200\n",
      "Epoch [160/1000], Loss: 0.3451\n",
      "Epoch [170/1000], Loss: 0.3504\n",
      "Epoch [180/1000], Loss: 0.2581\n",
      "Epoch [190/1000], Loss: 0.3228\n",
      "Epoch [200/1000], Loss: 0.3801\n",
      "Epoch [210/1000], Loss: 0.3256\n",
      "Epoch [220/1000], Loss: 0.3629\n",
      "Epoch [230/1000], Loss: 0.3382\n",
      "Epoch [240/1000], Loss: 0.3145\n",
      "Epoch [250/1000], Loss: 0.3420\n",
      "Epoch [260/1000], Loss: 0.3250\n",
      "Epoch [270/1000], Loss: 0.3312\n",
      "Epoch [280/1000], Loss: 0.3229\n",
      "Epoch [290/1000], Loss: 0.3254\n",
      "Epoch [300/1000], Loss: 0.3713\n",
      "Epoch [310/1000], Loss: 0.3534\n",
      "Epoch [320/1000], Loss: 0.2903\n",
      "Epoch [330/1000], Loss: 0.3632\n",
      "Epoch [340/1000], Loss: 0.3498\n",
      "Epoch [350/1000], Loss: 0.3290\n",
      "Epoch [360/1000], Loss: 0.4170\n",
      "Epoch [370/1000], Loss: 0.3686\n",
      "Epoch [380/1000], Loss: 0.3239\n",
      "Epoch [390/1000], Loss: 0.3340\n",
      "Epoch [400/1000], Loss: 0.3620\n",
      "Epoch [410/1000], Loss: 0.2795\n",
      "Epoch [420/1000], Loss: 0.3280\n",
      "Epoch [430/1000], Loss: 0.3687\n",
      "Epoch [440/1000], Loss: 0.3185\n",
      "Epoch [450/1000], Loss: 0.3194\n",
      "Epoch [460/1000], Loss: 0.3475\n",
      "Epoch [470/1000], Loss: 0.3311\n",
      "Epoch [480/1000], Loss: 0.3608\n",
      "Epoch [490/1000], Loss: 0.2910\n",
      "Epoch [500/1000], Loss: 0.3393\n",
      "Epoch [510/1000], Loss: 0.3316\n",
      "Epoch [520/1000], Loss: 0.3890\n",
      "Epoch [530/1000], Loss: 0.3462\n",
      "Epoch [540/1000], Loss: 0.3342\n",
      "Epoch [550/1000], Loss: 0.3455\n",
      "Epoch [560/1000], Loss: 0.3396\n",
      "Epoch [570/1000], Loss: 0.3009\n",
      "Epoch [580/1000], Loss: 0.3939\n",
      "Epoch [590/1000], Loss: 0.2598\n",
      "Epoch [600/1000], Loss: 0.3491\n",
      "Epoch [610/1000], Loss: 0.3643\n",
      "Epoch [620/1000], Loss: 0.3342\n",
      "Epoch [630/1000], Loss: 0.2863\n",
      "Epoch [640/1000], Loss: 0.2771\n",
      "Epoch [650/1000], Loss: 0.3048\n",
      "Epoch [660/1000], Loss: 0.2976\n",
      "Epoch [670/1000], Loss: 0.3423\n",
      "Epoch [680/1000], Loss: 0.3906\n",
      "Epoch [690/1000], Loss: 0.3987\n",
      "Epoch [700/1000], Loss: 0.2929\n",
      "Epoch [710/1000], Loss: 0.2479\n",
      "Epoch [720/1000], Loss: 0.3573\n",
      "Epoch [730/1000], Loss: 0.2846\n",
      "Epoch [740/1000], Loss: 0.3154\n",
      "Epoch [750/1000], Loss: 0.2872\n",
      "Epoch [760/1000], Loss: 0.2987\n",
      "Epoch [770/1000], Loss: 0.2872\n",
      "Epoch [780/1000], Loss: 0.3300\n",
      "Epoch [790/1000], Loss: 0.2834\n",
      "Epoch [800/1000], Loss: 0.2970\n",
      "Epoch [810/1000], Loss: 0.3066\n",
      "Epoch [820/1000], Loss: 0.2880\n",
      "Epoch [830/1000], Loss: 0.3145\n",
      "Epoch [840/1000], Loss: 0.3590\n",
      "Epoch [850/1000], Loss: 0.2798\n",
      "Epoch [860/1000], Loss: 0.2702\n",
      "Epoch [870/1000], Loss: 0.2718\n",
      "Epoch [880/1000], Loss: 0.2621\n",
      "Epoch [890/1000], Loss: 0.3115\n",
      "Epoch [900/1000], Loss: 0.3301\n",
      "Epoch [910/1000], Loss: 0.2846\n",
      "Epoch [920/1000], Loss: 0.3218\n",
      "Epoch [930/1000], Loss: 0.3686\n",
      "Epoch [940/1000], Loss: 0.3242\n",
      "Epoch [950/1000], Loss: 0.3476\n",
      "Epoch [960/1000], Loss: 0.2927\n",
      "Epoch [970/1000], Loss: 0.3012\n",
      "Epoch [980/1000], Loss: 0.3120\n",
      "Epoch [990/1000], Loss: 0.2838\n",
      "Epoch [1000/1000], Loss: 0.3146\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. Set Up Loss Function and Optimizer\n",
    "# -----------------------------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Train the Model\n",
    "# -----------------------------\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error: 0.15165792405605316\n",
      "Test MSE (scikit-learn): 0.15165792121422278\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluate the Model\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(device))\n",
    "    test_loss = criterion(predictions, y_test_tensor.to(device)).item()\n",
    "    print(\"Test Mean Squared Error:\", test_loss)\n",
    "\n",
    "# Optionally, to evaluate using scikit-learn's MSE:\n",
    "predictions_np = predictions.cpu().numpy()\n",
    "mse = mean_squared_error(y_test, predictions_np)\n",
    "print(\"Test MSE (scikit-learn):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE in Dollars: $32,532.60\n"
     ]
    }
   ],
   "source": [
    "predictions_original = scaler_y.inverse_transform(predictions_np.reshape(-1, 1))\n",
    "y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "mse_original = mean_squared_error(y_test_original, predictions_original)\n",
    "rmse_original = mse_original**0.5\n",
    "print(f\"Test RMSE in Dollars: ${rmse_original:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 9. Load Test Data and Predict\n",
    "# -----------------------------\n",
    "\n",
    "# Load test.csv\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# ✅ Ensure `top4_features` is defined\n",
    "if 'top4_features' not in locals():\n",
    "    raise ValueError(\"❌ `top4_features` is not defined. Make sure Step 3 ran correctly!\")\n",
    "\n",
    "# ✅ Ensure all training features exist in test data\n",
    "for col in top4_features:\n",
    "    if col not in test_data.columns:\n",
    "        print(f\"⚠ Warning: {col} is missing in test.csv! Filling with 0.\")\n",
    "        test_data[col] = 0  # Fill missing features with 0\n",
    "\n",
    "# ✅ Select only the top 4 features used during training\n",
    "X_test = test_data[top4_features].values  # Ensure correct shape\n",
    "\n",
    "# Use the same scaler fitted on the training data\n",
    "X_test = scaler_X.transform(X_test)  # This should now work correctly\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# Make Predictions\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor)\n",
    "\n",
    "# Convert predictions back to original scale (if SalePrice was standardized)\n",
    "test_predictions_np = test_predictions.cpu().numpy().flatten()\n",
    "test_predictions_original = scaler_y.inverse_transform(test_predictions_np.reshape(-1, 1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 10. Save Predictions to CSV\n",
    "# -----------------------------\n",
    "# The submission file should have columns: ID, SALEPRICE\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test_data[\"Id\"],  # 'Id' should match the column in your test.csv\n",
    "    \"SalePrice\": test_predictions_original\n",
    "})\n",
    "\n",
    "submission.to_csv('predictions.csv', index=False)\n",
    "print(\"Submission file saved as predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
